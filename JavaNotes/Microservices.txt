Central Configuration: A centralized, versioned configuration system, something like Zookeeper, changes to which are dynamically applied to running services.
Service discovery: Every running service should register itself with a service discovery server and the server tells everyone who is online. Just like a typical chat app. We don’t want to hard-code service endpoint address into one another.
Load balancing: Client side load balancing, so that you can apply complex balancing strategies and do caching, batching, fault tolerance, service discovery and handle multiple protocols.
Inter-process communication: We’ll need to implement an efficient inter-process communication strategy. It can be anything like REST or Thrift or asynchronous, message-based communication mechanisms such as AMQP or STOMP. We can also use efficient message formats such as Avro or Protocol Buffers since this won’t be used to communicate with outside world.
Authentication and security: We need to have a system for identifying authentication requirements for each resource and rejecting requests that do not satisfy them.
Non-blocking IO: API Gateway handles requests by invoking multiple backend services and aggregating the results. With some requests, such as a product details request, the requests to backend services are independent of one another. In order to minimize response time, the API Gateway should perform independent requests concurrently.
Eventual Consistency: We need to have a system in place to handle business transactions that span multiple services. When a service updates its database, it should publish an event and there should be a Message Broker that guarantees that events are delivered at least once to the subscribing services.
Fault Tolerance: We must avoid the situation whereby a single fault cascades into a system failure. API Gateway should never block indefinitely waiting for a downstream service. It should handle failures gracefully and return partial responses whenever possible.
Distributed Sessions: Ideally we should not have any state on server. Application state should be saved on client side. That’s one of the important principles of a RESTful service. But if you’ve an exception and you can’t avoid it, always have distributed sessions. Since client only communicates with API Gateway we’ll need to run multiple copies of it behind a load balancer because we don’t want API Gateway to become a bottleneck. This means that client’s subsequent requests can land on any of the running instances of API Gateway. We need to have a way to share the authentication info among various instances of API Gateway. We don’t want the client to re-authenticate every time its request falls on a different instance of API Gateway.
Distributed caching: We should have caching mechanisms at multiple levels to reduce client latency. Multiple levels simply means client, API Gateway and microservices should each have a reliable caching mechanism.
Detailed monitoring: We should be able to track meaningful data and statistics of each functional component in order to give us an accurate view of production. Proper alarms must be triggered in case of exceptions or high response times.
Dynamic Routing: API Gateway should be able to intelligently route the requests to microservices if it does not have a specific mapping to the requested resource. In other words, changes should not be required in API Gateway every time a microservice adds a new endpoint on its side.
Auto Scaling: Each component of our architecture including API Gateway should be horizontally scalable and should scale automatically when required even if it is deployed inside a container.
Polyglot Support: Since different microservices might be written in different languages or frameworks, the system should provide smooth service invocations and above mentioned features regardless of the language it is written in.
Smooth Deployment: Deployment of our microservices should be fast, independent and automated if possible.
Platform independent: To make efficient use of hardware and to keep our services independent of the platform on which it is deployed we should deploy our web services inside some container like the docker.
Log Aggregation: We should have a system in place which automatically keeps aggregating logs from all the microservices onto a file system. These logs might be used for various analytics later on